{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v36 数据增广.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPB98dP84w0Gn3pDxom9W3V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/For-Chance/BigDataPanel/blob/master/myDL/v36%20%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据增广"
      ],
      "metadata": {
        "id": "iaj2tisj0jME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在已有的数据集上，使得有更多的多样性\n",
        "\n",
        "切割\n",
        "- 从图片中切割一块，然后变形到固定形状"
      ],
      "metadata": {
        "id": "ISDDV7KqPm6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 常用的数据增广"
      ],
      "metadata": {
        "id": "WY2sWB201gY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "A0qA-82j1e1F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.set_figsize()\n",
        "img = d2l.Image.open('../img/cat1.jpg')\n",
        "d2l.plt.imshow(img);"
      ],
      "metadata": {
        "id": "Z_05LUkP1uV_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "13738de4-099a-4f76-ada7-56ccc4155888"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d2d1eb910add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_figsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.google.com.hk/imgres?imgurl=https%3A%2F%2Fi.guim.co.uk%2Fimg%2Fmedia%2F26392d05302e02f7bf4eb143bb84c8097d09144b%2F446_167_3683_2210%2Fmaster%2F3683.jpg%3Fwidth%3D1200%26height%3D1200%26quality%3D85%26auto%3Dformat%26fit%3Dcrop%26s%3D49ed3252c0b2ffb49cf8b508892e452d&imgrefurl=https%3A%2F%2Fwww.theguardian.com%2Flifeandstyle%2F2020%2Fsep%2F05%2Fwhat-cats-mean-by-miaow-japans-pet-guru-knows-just-what-your-feline-friend-wants&tbnid=BBEQz5BdOWu86M&vet=12ahUKEwj-_amXqI33AhUWhJQKHZ-9DR8QMygAegUIARDWAQ..i&docid=V4qL_jTRbB2FuM&w=1200&h=1200&q=cat&ved=2ahUKEwj-_amXqI33AhUWhJQKHZ-9DR8QMygAegUIARDWAQ'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.google.com.hk/imgres?imgurl=https%3A%2F%2Fi.guim.co.uk%2Fimg%2Fmedia%2F26392d05302e02f7bf4eb143bb84c8097d09144b%2F446_167_3683_2210%2Fmaster%2F3683.jpg%3Fwidth%3D1200%26height%3D1200%26quality%3D85%26auto%3Dformat%26fit%3Dcrop%26s%3D49ed3252c0b2ffb49cf8b508892e452d&imgrefurl=https%3A%2F%2Fwww.theguardian.com%2Flifeandstyle%2F2020%2Fsep%2F05%2Fwhat-cats-mean-by-miaow-japans-pet-guru-knows-just-what-your-feline-friend-wants&tbnid=BBEQz5BdOWu86M&vet=12ahUKEwj-_amXqI33AhUWhJQKHZ-9DR8QMygAegUIARDWAQ..i&docid=V4qL_jTRbB2FuM&w=1200&h=1200&q=cat&ved=2ahUKEwj-_amXqI33AhUWhJQKHZ-9DR8QMygAegUIARDWAQ'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):\n",
        "    Y = [aug(img) for _ in range(num_rows * num_cols)]\n",
        "    d2l.show_images(Y, num_rows, num_cols, scale=scale)"
      ],
      "metadata": {
        "id": "kxfnhIEk1u35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply(img, torchvision.transforms.RandomHorizontalFlip())"
      ],
      "metadata": {
        "id": "WJfBkXgc11FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratio 高宽比\n",
        "shape_aug = torchvision.transforms.RandomResizedCrop(\n",
        "    (200, 200), scale=(0.1, 1), ratio=(0.5, 2))\n",
        "apply(img, shape_aug)"
      ],
      "metadata": {
        "id": "4Bztys3812KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply(img, torchvision.transforms.ColorJitter(\n",
        "    brightness=0.5, contrast=0, saturation=0, hue=0))"
      ],
      "metadata": {
        "id": "pvWjEE-k131S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply(img, torchvision.transforms.ColorJitter(\n",
        "    brightness=0, contrast=0, saturation=0, hue=0.5))"
      ],
      "metadata": {
        "id": "rlafWRC515Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_aug = torchvision.transforms.ColorJitter(\n",
        "    brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n",
        "apply(img, color_aug)"
      ],
      "metadata": {
        "id": "BPkTaE5w160K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = torchvision.datasets.CIFAR10(train=True, root=\"../data\",\n",
        "                                          download=True)\n",
        "d2l.show_images([all_images[i][0] for i in range(32)], 4, 8, scale=0.8);"
      ],
      "metadata": {
        "id": "lJmCKcx1OvQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_augs = torchvision.transforms.Compose([\n",
        "     torchvision.transforms.RandomHorizontalFlip(),\n",
        "     torchvision.transforms.ToTensor()])\n",
        "\n",
        "test_augs = torchvision.transforms.Compose([\n",
        "     torchvision.transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "GQB5PmP5OyDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10(is_train, augs, batch_size):\n",
        "    dataset = torchvision.datasets.CIFAR10(root=\"../data\", train=is_train,\n",
        "                                           transform=augs, download=True)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                    shuffle=is_train, num_workers=d2l.get_dataloader_workers())\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "KNw-FjCyO18y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch_ch13(net, X, y, loss, trainer, devices):\n",
        "    \"\"\"用多GPU进行小批量训练\"\"\"\n",
        "    if isinstance(X, list):\n",
        "        # 微调BERT中所需（稍后讨论）\n",
        "        X = [x.to(devices[0]) for x in X]\n",
        "    else:\n",
        "        X = X.to(devices[0])\n",
        "    y = y.to(devices[0])\n",
        "    net.train()\n",
        "    trainer.zero_grad()\n",
        "    pred = net(X)\n",
        "    l = loss(pred, y)\n",
        "    l.sum().backward()\n",
        "    trainer.step()\n",
        "    train_loss_sum = l.sum()\n",
        "    train_acc_sum = d2l.accuracy(pred, y)\n",
        "    return train_loss_sum, train_acc_sum"
      ],
      "metadata": {
        "id": "f0mTWzZKO4qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
        "               devices=d2l.try_all_gpus()):\n",
        "    \"\"\"用多GPU进行模型训练\"\"\"\n",
        "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
        "                            legend=['train loss', 'train acc', 'test acc'])\n",
        "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "    for epoch in range(num_epochs):\n",
        "        # 4个维度：储存训练损失，训练准确度，实例数，特点数\n",
        "        metric = d2l.Accumulator(4)\n",
        "        for i, (features, labels) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            l, acc = train_batch_ch13(\n",
        "                net, features, labels, loss, trainer, devices)\n",
        "            metric.add(l, acc, labels.shape[0], labels.numel())\n",
        "            timer.stop()\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i + 1) / num_batches,\n",
        "                             (metric[0] / metric[2], metric[1] / metric[3],\n",
        "                              None))\n",
        "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
        "        animator.add(epoch + 1, (None, None, test_acc))\n",
        "    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n",
        "          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n",
        "          f'{str(devices)}')"
      ],
      "metadata": {
        "id": "MFh7NZAwO7kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, devices, net = 256, d2l.try_all_gpus(), d2l.resnet18(10, 3)\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) in [nn.Linear, nn.Conv2d]:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "net.apply(init_weights)\n",
        "\n",
        "def train_with_data_aug(train_augs, test_augs, net, lr=0.001):\n",
        "    train_iter = load_cifar10(True, train_augs, batch_size)\n",
        "    test_iter = load_cifar10(False, test_augs, batch_size)\n",
        "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    train_ch13(net, train_iter, test_iter, loss, trainer, 10, devices)"
      ],
      "metadata": {
        "id": "NFwiAaSAO9fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_with_data_aug(train_augs, test_augs, net)"
      ],
      "metadata": {
        "id": "_-rVMIU8O_Xz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}